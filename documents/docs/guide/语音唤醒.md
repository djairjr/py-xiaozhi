# Voice wake-up function

## Overview

py-xiaozhi integrates a high-precision voice wake-up function based on **Sherpa-ONNX**, supporting custom wake words and real-time detection. Use a lightweight keyword detection model to provide millisecond-level response speed.

## Wake word model

### Model download (required)

**Important Note**: The project does not contain model files and the configuration needs to be downloaded in advance.

### Official model download address

- **Official model list**: <https://csukuangfj.github.io/sherpa/onnx/kws/pretrained_models/index.html>
- **Recommended model**: `sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01`

### Download and configuration steps

#### 1. Download the model package

```bash
#Method 1: Direct download (recommended)
cd /Users/junsen/Desktop/workspace/py-xiaozhi
wget https://github.com/k2-fsa/sherpa-onnx/releases/download/kws-models/sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01.tar.bz2

# Unzip
tar xvf sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01.tar.bz2

#Method 2: Using ModelScope
pip install modelscope
python -c "
from modelscope import snapshot_download
snapshot_download('pkufool/sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01', cache_dir='./models')
"
```

#### 2. Configure model file

The model package contains the following files after downloading:

```
sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01/
├── encoder-epoch-12-avg-2-chunk-16-left-64.int8.onnx # Speed ​​priority
├── encoder-epoch-12-avg-2-chunk-16-left-64.onnx         # 
├── encoder-epoch-99-avg-1-chunk-16-left-64.int8.onnx # Speed ​​priority
├── encoder-epoch-99-avg-1-chunk-16-left-64.onnx # Precision priority
├── decoder-epoch-12-avg-2-chunk-16-left-64.onnx         #
├── decoder-epoch-99-avg-1-chunk-16-left-64.onnx # Precision priority
├── joiner-epoch-12-avg-2-chunk-16-left-64.int8.onnx # Speed ​​priority
├── joiner-epoch-12-avg-2-chunk-16-left-64.onnx          #
├── joiner-epoch-99-avg-1-chunk-16-left-64.int8.onnx # Speed ​​priority
├── joiner-epoch-99-avg-1-chunk-16-left-64.onnx # Precision first
├── tokens.txt # Token mapping table (required)
├── keywords_raw.txt # Original keywords (optional, used for generation)
├── keywords.txt                  # 现成的
├── test_wavs/ # Test audio (optional)
├── configuration.json # Model meta information (optional)
└── README.md # Documentation (optional)
```

#### 3. Select configuration plan

**Option 1: Accuracy first (recommended)**

```bash
cd sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01

# Copy accuracy priority epoch-99 fp32 three-piece set
cp encoder-epoch-99-avg-1-chunk-16-left-64.onnx ../models/encoder.onnx
cp decoder-epoch-99-avg-1-chunk-16-left-64.onnx ../models/decoder.onnx  
cp joiner-epoch-99-avg-1-chunk-16-left-64.onnx ../models/joiner.onnx

# Copy supporting files
cp tokens.txt ../models/tokens.txt
cp keywords_raw.txt ../models/keywords_raw.txt # Optional
```

**Option 2: Speed ​​priority**

```bash
cd sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01

# Copy speed priority epoch-99 int8 three-piece set
cp encoder-epoch-99-avg-1-chunk-16-left-64.int8.onnx ../models/encoder.onnx
cp decoder-epoch-99-avg-1-chunk-16-left-64.onnx ../models/decoder.onnx
cp joiner-epoch-99-avg-1-chunk-16-left-64.int8.onnx ../models/joiner.onnx

# Copy supporting files
cp tokens.txt ../models/tokens.txt
```

**Note**:

- **Don't mix fp32 and int8**: the three model files must maintain consistent accuracy
- **Prefer epoch-99**: more complete training and higher accuracy than epoch-12
- **Required files**: `encoder.onnx` + `decoder.onnx` + `joiner.onnx` + `tokens.txt` + `keywords.txt`

### Final model file structure

After configuration is complete, your models directory should contain:

```
models/
├── encoder.onnx # Encoder model (after rename)
├── decoder.onnx # Decoder model (after rename)
├── joiner.onnx # Connector model (after rename)
├── tokens.txt # Pinyin Token mapping table (228 lines version)
├── keywords.txt # Keyword configuration file (needs to be created)
└── keywords_raw.txt # Original keyword file (optional)
```

### Model performance comparison

| Model version | File size | Inference speed | Recognition accuracy | Resource usage | Recommended scenarios |
|---------|---------|---------|---------|---------|---------|
| **epoch-99 fp32** | ~13MB | Moderate | Highest | Moderate | **Desktop (Recommended)** |
| **epoch-99 int8** | ~4MB | Fast | High | Low | Mobile/resource constrained |
| **epoch-12 fp32** | ~13MB | Medium | Medium-High | Medium | General use |
| **epoch-12 int8** | ~4MB | Fastest | Medium | Lowest | Extremely fast response to demand |

## Enable voice wake-up

### Configuration file settings

Edit `config/config.json`:

```json
{
  "WAKE_WORD_OPTIONS": {
    "USE_WAKE_WORD": true,
    "MODEL_PATH": "models",
    "NUM_THREADS": 4,
    "PROVIDER": "cpu",
    "MAX_ACTIVE_PATHS": 2,
    "KEYWORDS_SCORE": 1.8,
    "KEYWORDS_THRESHOLD": 0.2,
    "NUM_TRAILING_BLANKS": 1
  }
}
```

### Detailed explanation of configuration parameters

| Parameters | Default value | Description | Tuning suggestions |
|------|--------|------|----------|
| `USE_WAKE_WORD` | `true` | Enable voice wake-up function | - |
| `MODEL_PATH` | `"models"` | Model file directory | Make sure the path is correct |
| `NUM_THREADS` | `4` | Number of processing threads | If the computer performance is good, it can be set to 6-8 |
| `PROVIDER` | `"cpu"` | Inference engine | Optional: cpu, cuda, coreml |
| `MAX_ACTIVE_PATHS` | `2` | Number of search paths | Reduce the lifting speed and increase the lifting accuracy |
| `KEYWORDS_SCORE` | `1.8` | Keyword enhancement score | Improve to reduce false detections, reduce to increase sensitivity |
| `KEYWORDS_THRESHOLD` | `0.2` | Detection threshold | Lower to increase sensitivity, increase to reduce false detections |
| `NUM_TRAILING_BLANKS` | `1` | Number of trailing blanks | Usually kept at 1 |

## Custom wake word

### Currently supported wake words

```
1. Xiaoai classmates (x iǎo ài t óng x ué)
2. Hello (n ǐ h ǎo w èn w èn)
3. Xiaoyi Xiaoyi (x iǎo y ì x iǎo y ì)
4. Xiaomi Xiaomi (x iǎo m ǐ x iǎo m ǐ)
5. Hello Xiaozhi (n ǐ h ǎo x iǎo zh ì)
6. Jarvis (j iā w éi s ī)
```

### Add new wake word

#### Method 1: Edit keyword file

Edit `models/keywords.txt` and add according to the format:

```
# Format: Pinyin decomposition @Chinese original text
x iǎo zh ì @小智
n ǐ h ǎo x iǎo zh ì @你好小智
j iā w éi s ī @jarvis
k āi sh ǐ g ōng z uò @start working
```

#### Method 2: Use Pinyin Conversion Tool

```python
from pypinyin import lazy_pinyin, Style

def generate_keyword_line(text):
    pinyin_list = lazy_pinyin(text, style=Style.TONE3, neutral_tone_with_five=True)
    processed_pinyin = [py.rstrip('12345') for py in pinyin_list]
    pinyin_str = ' '.join(processed_pinyin)
    return f'{pinyin_str} @{text}'

# Generate new wake word
wake_words = ['Little Assistant', 'Start work', 'Friday']
for word in wake_words:
    print(generate_keyword_line(word))
```

### Wake word selection suggestions

#### Recommended wake word features

- **Medium length**: 2-4 characters
- **Clear pronunciation**: avoid confusion of similar sounds
- **Uniqueness**: Avoid common words used in daily conversations
- **Catchy**: Easy to remember and pronounce

#### Examples of good wake words

```
- Hello Xiaozhi # 4 words, unique and clear
- Jarvis # 3 words, unique, technological sense
- Start working # 4 words, clear intention
- Assistant # 3 words, simple and easy to remember
```

#### Avoid using

```
- Hmm # is too short, easy to accidentally touch
- Hello # is too commonly used
- Please help me make a plan # too long
- thank you #daily phrases
```

## How to use

### Start the process

1. **Start the program**:

   ```bash
   cd /Users/junsen/Desktop/workspace/py-xiaozhi
   python main.py
   ```

2. **Model loading**:
- The system automatically loads the Sherpa-ONNX model
- Initialize keyword detector
- Enter wake word listening state

3. **Voice wakeup**:
- Speak the configured wake word clearly
- The system automatically switches to LISTENING state
- Start a voice conversation

### Usage tips

#### Best way to wake up

- **Moderate volume**: Normal speaking volume
- **Speak naturally**: not too fast or too slow
- **Clear pronunciation**: pay special attention to the intonation
- **Quiet Environment**: Reduce background noise

## Performance optimization

### Speed ​​optimization configuration

```json
{
  "WAKE_WORD_OPTIONS": {
"NUM_THREADS": 6, // Increase the number of threads
"MAX_ACTIVE_PATHS": 1, // Reduce search paths
"KEYWORDS_THRESHOLD": 0.15, // Lower the threshold to increase sensitivity
"KEYWORDS_SCORE": 1.5 // Reduce the score improvement speed
  }
}
```

### Precision optimization configuration

```json
{
  "WAKE_WORD_OPTIONS": {
"NUM_THREADS": 4, // Moderate number of threads
"MAX_ACTIVE_PATHS": 3, // Add search paths
"KEYWORDS_THRESHOLD": 0.25, // Increase the threshold to reduce false detections
"KEYWORDS_SCORE": 2.2 // Improve score to enhance accuracy
  }
}
```

### Performance Monitoring

Check current performance:

```python
# View statistics in the application
stats = wake_word_detector.get_performance_stats()
print(f"Engine: {stats['engine']}")
print(f"Number of threads: {stats['num_threads']}")
print(f"Detection threshold: {stats['keywords_threshold']}")
print(f"Running status: {stats['is_running']}")
```

## troubleshooting

### FAQ

#### 1. No response to wake word

**Symptoms**: No response when speaking the wake word

**Solution**:

```bash
# Check configuration
grep -A 10 "WAKE_WORD_OPTIONS" config/config.json

# Check model file
ls -la models/

# Test function
python test_new_keywords.py
```

#### 2. Slow response speed

**Symptoms**: Large delay in wake word recognition

**Solution**:

```json
{
  "WAKE_WORD_OPTIONS": {
"KEYWORDS_THRESHOLD": 0.15, // Lower the threshold
"NUM_THREADS": 6, // Add threads
"MAX_ACTIVE_PATHS": 1 // Reduce search paths
  }
}
```

#### 3. Frequent false detections

**Symptoms**: Frequent false triggering of wake-ups

**Solution**:

```json
{
  "WAKE_WORD_OPTIONS": {
"KEYWORDS_THRESHOLD": 0.3, // Increase the threshold
"KEYWORDS_SCORE": 2.5, // Increase score
"MAX_ACTIVE_PATHS": 3 // Add search paths
  }
}
```

#### 4. Model loading failed

**Symptoms**: Model file error during startup

**Solution**:

```bash
# Check file integrity
ls -la models/
file models/*.onnx
file models/tokens.txt

# Revalidate the model
python test_new_keywords.py
```

### Debugging commands

```bash
# View system logs
tail -f logs/app.log | grep -i kws

# Monitor performance
top -p $(pgrep -f "python main.py")

# Test audio device
python -c "import sounddevice as sd; print(sd.query_devices())"
```

## Advanced configuration

### Environment adaptation

#### Quiet environment (office)

```json
{
  "WAKE_WORD_OPTIONS": {
    "KEYWORDS_THRESHOLD": 0.15,
    "KEYWORDS_SCORE": 1.5,
    "MAX_ACTIVE_PATHS": 1
  }
}
```

#### Noisy environment (open space)

```json
{
  "WAKE_WORD_OPTIONS": {
    "KEYWORDS_THRESHOLD": 0.25,
    "KEYWORDS_SCORE": 2.5,
    "MAX_ACTIVE_PATHS": 3
  }
}
```

### Integrate with AEC

Voice wake-up perfectly integrated with Acoustic Echo Cancellation (AEC):

```json
{
  "AEC_OPTIONS": {
"ENABLED": true, // AEC provides clean audio for wake words
"ENABLE_PREPROCESS": true // Noise suppression improves detection accuracy
  },
  "WAKE_WORD_OPTIONS": {
"USE_WAKE_WORD": true // Use AEC processed audio
  }
}
```

### Performance Benchmark

Expected performance in standard configuration:

| Indicator | Target value | Description |
|------|--------|------|
| **Response Delay** | < 1 second | From speaking to detection completion |
| **Detection accuracy** | > 95% | Correctly identify and set wake words |
| **False Detection Rate** | < 5% | False Trigger Frequency |
| **CPU usage** | < 30% | Resource consumption during continuous operation |
| **Memory** | < 100MB | Model and buffer memory usage |

## Summarize

**Sherpa-ONNX voice wake-up function features**:

- **High Accuracy**: End-to-end detection based on deep learning
- **Low Latency**: Millisecond-level response speed
- **Low resources**: lightweight model, suitable for PC running
- **Customizable**: Supports custom wake words
- **Easy to Integrate**: Perfect integration with existing audio processing

Now you can enjoy a smart, fast and accurate voice wake-up experience!
